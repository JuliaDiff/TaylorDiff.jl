<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Theory · TaylorDiff.jl</title><meta name="title" content="Theory · TaylorDiff.jl"/><meta property="og:title" content="Theory · TaylorDiff.jl"/><meta property="twitter:title" content="Theory · TaylorDiff.jl"/><meta name="description" content="Documentation for TaylorDiff.jl."/><meta property="og:description" content="Documentation for TaylorDiff.jl."/><meta property="twitter:description" content="Documentation for TaylorDiff.jl."/><meta property="og:url" content="https://juliadiff.org/TaylorDiff.jl/theory/"/><meta property="twitter:url" content="https://juliadiff.org/TaylorDiff.jl/theory/"/><link rel="canonical" href="https://juliadiff.org/TaylorDiff.jl/theory/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">TaylorDiff.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/halley/">Efficient Halley&#39;s method for nonlinear solving</a></li></ul></li><li class="is-active"><a class="tocitem" href>Theory</a><ul class="internal"><li><a class="tocitem" href="#Arithmetic-of-polynomials"><span>Arithmetic of polynomials</span></a></li><li><a class="tocitem" href="#Pushforward-rule-for-elementary-functions"><span>Pushforward rule for elementary functions</span></a></li><li><a class="tocitem" href="#Generic-pushforward-rule"><span>Generic pushforward rule</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Theory</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Theory</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaDiff/TaylorDiff.jl/blob/main/docs/src/theory.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Theory"><a class="docs-heading-anchor" href="#Theory">Theory</a><a id="Theory-1"></a><a class="docs-heading-anchor-permalink" href="#Theory" title="Permalink"></a></h1><p>TaylorDiff.jl is an operator-overloading based forward-mode automatic differentiation (AD) package. &quot;Forward-mode&quot; implies that the basic capability of this package is that, for function <span>$f:\mathbb R^n\to\mathbb R^m$</span>, place to evaluate derivative <span>$x\in\mathbb R^n$</span> and direction <span>$l\in\mathbb R^n$</span>, we compute</p><p class="math-container">\[f(x),\partial f(x)\times v,\partial^2f(x)\times v\times v,\cdots,\partial^pf(x)\times v\times\cdots\times v\]</p><p>i.e., the function value and the directional derivative up to order <span>$p$</span>.  This notation might be unfamiliar to Julia users that had experience with other AD packages, but <span>$\partial f(x)$</span> is simply the jacobian <span>$J$</span>, and <span>$\partial f(x)\times v$</span> is simply the Jacobian-vector product (JVP). In other words, this is a simple generalization of Jacobian-vector product to Hessian-vector-vector product, and to even higher orders.</p><p>The main advantage of doing this instead of doing <span>$p$</span> first-order Jacobian-vector products is that nesting first-order AD results in exponential scaling w.r.t <span>$p$</span>, while this method, also known as Taylor mode, should scale (almost) linearly w.r.t <span>$p$</span>.  We will see the reason of this claim later.</p><p>In order to achieve this, we assume that <span>$f$</span> is a nested function <span>$f_k\circ\cdots\circ f_2\circ f_1$</span>, where each <span>$f_i$</span> is a basic and simple function, also called &quot;primitive&quot;.  We need to figure out how to propagate the derivatives through each step.  In first order AD, this is achieved by the &quot;dual&quot; pair <span>$x_0+x_1\varepsilon$</span>, where <span>$\varepsilon^2=0$</span>, and for each primitive we make a method overload</p><p class="math-container">\[f(x_0+x_1\varepsilon)=f(x_0)+\partial f(x_0) x_1\varepsilon\]</p><p>Similarly in higher-order AD, we need for each primitive a method overload for a truncated Taylor polynomial up to order <span>$p$</span>, and in this polynomial we will use <span>$t$</span> instead of <span>$\varepsilon$</span> to denote the sensitivity. &quot;Truncated&quot; means <span>$t^{p+1}=0$</span>, similar as what we defined for dual numbers. So</p><p class="math-container">\[f(x_0+x_1t+x_2t^2+\cdots+x_pt^p)=?\]</p><p>What is the math expression that we should put into the question mark?  That specific expression is called the &quot;pushforward rule&quot;, and we will talk about how to derive the pushforward rule below.</p><h2 id="Arithmetic-of-polynomials"><a class="docs-heading-anchor" href="#Arithmetic-of-polynomials">Arithmetic of polynomials</a><a id="Arithmetic-of-polynomials-1"></a><a class="docs-heading-anchor-permalink" href="#Arithmetic-of-polynomials" title="Permalink"></a></h2><p>Before deriving pushforward rules, let&#39;s first introduce several basic properties of polynomials.</p><p>If <span>$x(t)$</span> and <span>$y(t)$</span> are both truncated Taylor polynomials, i.e.</p><p class="math-container">\[\begin{aligned}
x&amp;=x_0+x_1t+\cdots+x_pt^p\\
y&amp;=y_0+y_1t+\cdots+y_pt^p
\end{aligned}\]</p><p>Then it&#39;s obvious that the polynomial addition and subtraction should be</p><p class="math-container">\[(x\pm y)_k=x_k\pm y_k\]</p><p>And with some derivation we can also get the polynomial multiplication rule</p><p class="math-container">\[(x\times y)_k=\sum_{i=0}^kx_iy_{k-i}\]</p><p>The polynomial division rule is less obvious, but if <span>$x/y=z$</span>, then equivalently <span>$x=yz$</span>, i.e.</p><p class="math-container">\[\left(\sum_{i=0}^py_it^i\right)\left(\sum_{i=0}^pz_it^i\right)=\sum_{i=0}^px_it^i\]</p><p>if we relate the coefficient of <span>$t^k$</span> on both sides we get</p><p class="math-container">\[\sum_{i=0}^k z_iy_{k-i}=x_k\]</p><p>so, equivalently,</p><p class="math-container">\[z_k=\frac1{y_0}\left(x_k-\sum_{i=0}^{k-1}z_iy_{k-1}\right)\]</p><p>This is a recurrence relation, which means that we can first get <span>$z_0=x_0/y_0$</span>, and then get <span>$z_1$</span> using <span>$z_0$</span>, and then get <span>$z_2$</span> using <span>$z_0,z_1$</span> etc.</p><h2 id="Pushforward-rule-for-elementary-functions"><a class="docs-heading-anchor" href="#Pushforward-rule-for-elementary-functions">Pushforward rule for elementary functions</a><a id="Pushforward-rule-for-elementary-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Pushforward-rule-for-elementary-functions" title="Permalink"></a></h2><p>Let&#39;s now consider how to derive the pushforward rule for elementary functions. We will use <span>$\exp$</span> and <span>$\log$</span> as two examples.</p><p>If <span>$x(t)$</span> is a polynomial and we want to get <span>$e(t)=\exp(x(t))$</span>, we can actually get that by formulating an ordinary differential equation:</p><p class="math-container">\[e&#39;(t)=\exp(x(t))x&#39;(t);\quad  e_0=\exp(x_0)\]</p><p>If we expand both <span>$e$</span> and <span>$x$</span> in the equation, we will get</p><p class="math-container">\[\sum_{i=1}^pie_it^{i-1}=\left(\sum_{i=0}^{p-1} e_it^i\right)\left(\sum_{i=1}^pix_it^{i-1}\right)\]</p><p>relating the coefficient of <span>$t^{k-1}$</span> on both sides, we get</p><p class="math-container">\[ke_k=\sum_{i=0}^{k-1}e_i\times (k-i)x_{k-i}\]</p><p>This is, again, a recurrence relation, so we can get <span>$e_1,\cdots,e_p$</span> step-by-step.</p><p>If <span>$x(t)$</span> is a polynomial and we want to get <span>$l(t)=\log(x(t))$</span>, we can actually get that by formulating an ordinary differential equation:</p><p class="math-container">\[l&#39;(t)=\frac1xx&#39;(t);\quad  l_0=\log(x_0)\]</p><p>If we expand both <span>$l$</span> and <span>$x$</span> in the equation, the RHS is simply polynomial divisions, and we get</p><p class="math-container">\[l_k=\frac1{x_0}\left(x_k-\frac1k\sum_{i=1}^{k-1}il_ix_{k-j}\right)\]</p><hr/><p>Now notice the difference between the rule for <span>$\exp$</span> and <span>$\log$</span>: the derivative of exponentiation is itself, so we can obtain from recurrence relation; the derivative of logarithm is <span>$1/x$</span>, an algebraic expression in <span>$x$</span>, so it can be directly computed.  Similarly, we have <span>$(\tan x)&#39;=1+\tan^2x$</span> but <span>$(\arctan x)&#39;=(1+x^2)^{-1}$</span>. We summarize (omitting proof) that</p><ul><li>Every <span>$\exp$</span>-like function (like <span>$\sin$</span>, <span>$\cos$</span>, <span>$\tan$</span>, <span>$\sinh$</span>, ...)&#39;s derivative is somehow recursive</li><li>Every <span>$\log$</span>-like function (like <span>$\arcsin$</span>,  <span>$\arccos$</span>, <span>$\arctan$</span>, <span>$\operatorname{arcsinh}$</span>, ...)&#39;s derivative is algebraic</li></ul><p>So all of the elementary functions have an easy pushforward rule that can be computed within <span>$O(p^2)$</span> time. Note that this is an elegant and straightforward corollary from the definition of &quot;elementary function&quot; in differential algebra.</p><h2 id="Generic-pushforward-rule"><a class="docs-heading-anchor" href="#Generic-pushforward-rule">Generic pushforward rule</a><a id="Generic-pushforward-rule-1"></a><a class="docs-heading-anchor-permalink" href="#Generic-pushforward-rule" title="Permalink"></a></h2><p>For a generic <span>$f(x)$</span>, if we don&#39;t bother deriving the specific recurrence rule for it, we can still automatically generate a pushforward rule in the following manner. Let&#39;s denote the derivative of <span>$f$</span> w.r.t <span>$x$</span> to be <span>$d(x)$</span>, then for <span>$f(t)=f(x(t))$</span>  we have</p><p class="math-container">\[f&#39;(t)=d(x(t))x&#39;(t);\quad f(0)=f(x_0)\]</p><p>when we expand <span>$f$</span> and <span>$x$</span> up to order <span>$p$</span> into this equation, we notice that only order <span>$p-1$</span> is needed for <span>$d(x(t))$</span>.  In other words, we turn a problem of finding <span>$p$</span>-th order pushforward for <span>$f$</span>, to a problem of finding <span>$(p-1)$</span>-th order pushforward for <span>$d$</span>, and we can recurse down to the first order.  The first-order derivative expressions are captured from ChainRules.jl, which makes this process fully automatic.</p><p>This strategy is in principle equivalent to nesting first-order differentiation, which could potentially lead to exponential scaling; however, in practice there is a huge difference.  This generation of pushforward rules happens at <strong>compile time</strong>, which gives the compiler a chance to check redundant expressions and optimize it down to quadratic time.  The compiler has stack limits but this should work at least up to order 100.</p><p>In the current implementation of TaylorDiff.jl, all <span>$\log$</span>-like functions&#39; pushforward rules are generated by this strategy, since their derivatives are simple algebraic expressions; some <span>$\exp$</span>-like functions, like <span>$\sinh$</span>, are also generated; several of the most-often-used <span>$\exp$</span>-like functions are hand-written with hand-derived recurrence relations.</p><p>If you find that the code generated by this strategy is slow, please file an issue and we will look into it.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/halley/">« Efficient Halley&#39;s method for nonlinear solving</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 27 November 2025 13:20">Thursday 27 November 2025</span>. Using Julia version 1.12.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
